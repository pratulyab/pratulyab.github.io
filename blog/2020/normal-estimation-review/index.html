<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Pratulya  Bubna | Surface Normal Estimation in Point Clouds</title>
<meta name="description" content="Personal Webpage - Pratulya Bubna
">


	<meta name="keywords" content="surface normal, normal estimation, 3d normal, point cloud, pcpnet, nestinet, local plane constraint, graph based normal estimation, point cloud normal estimation, pca, surface fitting" />


<!-- Open Graph -->

<meta property="og:site_name" content="Personal Webpage - Pratulya Bubna
" />
<meta property="og:type" content="object" />
<meta property="og:title" content="" />
<meta property="og:url" content="/blog/2020/normal-estimation-review/" />
<meta property="og:description" content="Surface Normal Estimation in Point Clouds" />
<meta property="og:image" content="/assets/img/blog/normal-estimation/traditional.gif" />


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/blog/2020/normal-estimation-review/">

<!-- Theming-->

  <script src="/assets/js/theme.js"></script>


    
<!-- MathJax -->
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


    <script src="/assets/js/distillpub/template.v2.js"></script>
    <script src="/assets/js/distillpub/transforms.v2.js"></script>
    
  </head>
<!--
  <d-front-matter>
    <script async type="text/json">{
      "title": "Surface Normal Estimation in Point Clouds",
      "description": "A survey on surface normal estimation in 3D point clouds",
      "published": "2020-11-15 05:30:00 +0530",
      "authors": [
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>
-->
  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       <span class="font-weight-bold">Pratulya</span>   Bubna
      </a>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item active">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                projects
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                publications
                
              </a>
          </li>
          
          
          
            <div class="toggle-container">
              <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="post distill">

      <d-title>
        <h1>Surface Normal Estimation in Point Clouds</h1>
        <p>A survey on surface normal estimation in 3D point clouds</p>
    	<p>November 15, 2020 • Pratulya Bubna</p>
      </d-title>

	  
<!--      <d-byline></d-byline> -->

      <d-article style="text-align: justify;">
        <h2 id="surface-normals">Surface Normals</h2>
<p>Have you ever encountered a semi-rendered object in a game? Perhaps in a game you were able to see through inside a box, even though from outside it seemed a solid object? Well, that happens sometimes because of rendering tricks that gaming engines use.</p>

<p>This usually is the case as, intuitively enough, polygon surfaces that aren’t facing the camera, are not rendered; thereby, providing speed-ups in generating frames. Moreover, the saved computation resources can be spent optimizing the visible surfaces.</p>

<p>What determines a surface’s orientation is a normal to it at a point. In 3D computer graphics, it is of great utility to determine a surface’s orientation towards a light source. This piece of information helps in performing lighting computations, <em>eg. shading</em> and achieving other visual effects.</p>

<blockquote>
  A normal to a surface at point P is a vector perpendicular to the tangent plane of the surface at P (see below-left image)
</blockquote>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/blog/normal-estimation/1.png">
    </div>
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/blog/normal-estimation/2.png">
    </div>
</div>
<div class="caption">
    Fig 1: (left) Normal to a surface at a point is same as normal to the tangent to surface at that point
    (right) Normals to a curved surface (credits: wikipedia <d-footnote><a href="https://en.wikipedia.org/wiki/Normal_(geometry)">https://en.wikipedia.org/wiki/Normal_(geometry)</a></d-footnote>)
</div>

<h2 id="normal-estimation-in-point-clouds">Normal Estimation in Point Clouds</h2>
<ul>
  <li><a href="#intro">Introduction</a></li>
  <li><a href="#traditional">Traditional Approaches</a></li>
  <li>
<a href="#data-driven">Data-Driven Approaches</a>
    <ul>
      <li>
<a href="#pcpnet">PCPNet</a> <d-cite key="guerrero2018pcpnet"></d-cite>
</li>
      <li>
<a href="#nestinet">Nesti-Net</a> <d-cite key="ben2019nesti"></d-cite>
</li>
      <li>
<a href="#lpfc">Local Plane Feature Constraint</a> <d-cite key="zhou2020normal"></d-cite>
</li>
      <li>
<a href="#gcn">Graph Convolution Network (GCN) based</a> <d-cite key="pistilli2020point"></d-cite>
</li>
      <li>Deep Iterative <d-cite key="lenssen2020deep"></d-cite>
</li>
      <li>Hough Transform <d-cite key="boulch2012fast"></d-cite>
</li>
    </ul>
  </li>
</ul>

<p><a name="intro"></a></p>
<h3 id="introduction">Introduction</h3>

<p>A point cloud from a dataset (say, PCPNet Dataset) represents a set of points <strong>sampled</strong> from an underlying surface. Inherent imperfections such as <em>varying sampling density, noise, missing data,</em> however lie in the point cloud data.</p>

<blockquote>
A point cloud is a set of data points in a space that represents a 3D shape or object. Each point has its set of X,Y,Z coordinates. <d-footnote><a href="https://en.wikipedia.org/wiki/Point_cloud">https://en.wikipedia.org/wiki/Point_cloud</a></d-footnote>
</blockquote>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/blog/normal-estimation/3.png">
    </div>
</div>
<div class="caption">
    point cloud (left) sampled from the original surface (right)
</div>

<p><em><u>Problem Statement:</u></em>  Given a point cloud, process it <strong>directly</strong> to infer the surface normals.<br>
Note that this problem is different from processing a point cloud <em>indirectly</em>, where it is first converted to an <strong>intermediate</strong> representation, <em>eg. mesh,</em> and then processed.<br></p>

<p>More closely, the problem requires us to be able to infer the underlying surface from the point cloud representation, from which the normals can be estimated at the given points.</p>
<blockquote>
Given a geometric surface, it’s usually trivial to infer the direction of the normal at a certain point on the surface as the vector perpendicular to the surface at that point.
</blockquote>

<p>Making use of local surface properties such as normals and curvature as additional features for the point clouds has shown improvement in downstream tasks such as reconstruction, segmentation, denoising etc.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/blog/normal-estimation/issues.jpg">
    </div>
</div>
<div class="caption">
    issues inherent to point cloud data while estimating normals (credits: <d-footnote><a href="https://www.boulch.eu/files/talks/2016_sgp_normals_slides.pdf">Boulch, Alexandre et al.  "Deep Learning for Robust Normal Estimation in Unstructured Point Clouds"</a></d-footnote> )
</div>

<p><a name="traditional"></a></p>
<div class="l-body"><hr style="margin:0;"></div>

<h3 id="traditional-approaches">Traditional Approaches</h3>
<p>The traditional approaches to estimate normal at a point P involve <strong>fitting a surface to a patch</strong> of local neighborhood points around <code class="language-plaintext highlighter-rouge">P</code> and then calculating the normal analytically. For instance, <d-cite key="hoppe1992surface"></d-cite> utilizes PCA to fit a low-order surface on the <code class="language-plaintext highlighter-rouge">r-ball</code> neighborhood surrounding <code class="language-plaintext highlighter-rouge">P</code>, and outputs the eigenvector with minimum eigenvalue as the normal at <code class="language-plaintext highlighter-rouge">P</code>. In other words, normal at <code class="language-plaintext highlighter-rouge">P</code> is in the direction of the vector representing least variance. (PCA finds an orthogonal basis that best represents data by finding eigenvectors in directions of maximum variances.)</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/blog/normal-estimation/traditional.gif">
    </div>
</div>
<div class="caption">
    Fitting a surface to a patch (credits: Ben-Shabat et al. <d-cite key="ben2019nesti"></d-cite>)
</div>

<p>Other approaches try fitting higher-order surfaces such as spherical surfaces, jets. <d-cite key="CAZALS2005121"></d-cite> There’s work involving ideas from Voronio diagrams to achieve sharper results.</p>

<p>Given the orientation of a normal—a global property, techniques such as <strong>Poisson Surface Reconstruction</strong> can be used to reconstruct the mesh. However, most of the approaches tend to regress only the direction of the normal—a local property, and not the orientation. Orientation of the normals can be determined as a post-processing step though, using some approaches. <strong>Minimum Spanning Trees (MST)</strong> based approaches work on the intuition that parallel tangent plances in a neighborhoood should have similar normals, and thus propagate orientations using MST.</p>

<p><a name="data-driven"></a></p>
<h3 id="data-driven-approaches">Data-Driven Approaches</h3>
<p>The <strong>fundamental problem</strong> with the traditional approaches is the sensitivity to the choice of hyperparameters such as the <em>radius of the neighborhood</em>, for one, which leads to problematic results at the borders (corners, edges). Even though a <em>small</em> radius might be preferred to appropriately constrain the neighborhood and output fine normal estimations, it is sensitive to outliers; thereby, leading to inaccurate estimations at the borders. On the other hand, a <em>large</em> radius would oversmoothen (average) the estimates at these sharp features.</p>

<p>To overcome such tradeoffs between robustness to noise and accuracy of fine details, SOTA approaches are utilizing <strong>data-driven methods</strong>.</p>

<p>To put it into persepective, normal estimation in point clouds is a regression problem and {<code class="language-plaintext highlighter-rouge">L2</code>, <code class="language-plaintext highlighter-rouge">RMSE</code>} loss can be utilized for training the deep learning architecture.</p>

<p>Some common datasets include PCPNet Dataset, NYU Depth V2, ScanNet.</p>

<p>Now, let’s look at some of the deep learning based approaches for estimating local 3D shape properties in point clouds:</p>

<div class="l-body"><hr style="margin:0;"></div>

<!------- PCPNet ------->
<p><a name="pcpnet"></a></p>
<h3 id="pcpnet-">PCPNet <d-cite key="guerrero2018pcpnet"></d-cite>
</h3>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/blog/normal-estimation/pcpnet.png">
    </div>
</div>
<div class="caption">
    Single-scale and multi-scale PCPNet archicture.
</div>
<ul>
  <li>PCPNet has a PointNet <d-cite key="qi2017pointnet"></d-cite> inspired architecture.
    <ul>
      <li>computes per-point features</li>
      <li>uses a <strong>Spatial Transformer Network</strong> (STN) to output a <strong>Quaternion</strong> (rotation) instead of 3x3 matrix, to convert input into a canonical pose.</li>
    </ul>
  </li>
  <li>The original PointNet architecture excels in <em>global feature learning</em> which is good for classification tasks. However, to estimate local surface properties as in our case, local-level features are suited better. Hence, PCPNet makes use of <strong>local patches</strong> (<em>neighborhood</em>) centered at sampled points.
    <ul>
      <li>helps in preserving features around high-curvature regions, and thus allow more robust results.</li>
      <li>uses <code class="language-plaintext highlighter-rouge">k-dim</code> patch feature vectors to regress normals, curvature and/or both (in joint training)</li>
    </ul>
  </li>
  <li>The <strong>multi-scale</strong> variant of PCPNet takes patches of varied neighborhood sizes and concatenates into a single vector to regress properties. This, in practice, works better than single-scale.</li>
  <li>It can output <strong>both</strong> <em>oriented</em> and <em>unoriented</em> normals, as well as <em>principal curvature</em>.</li>
</ul>

<div class="l-body"><hr style="margin:0;"></div>

<!------- Nesti-Net ------->
<p><a name="nestinet"></a></p>
<h3 id="nesti-net-">Nesti-Net <d-cite key="ben2019nesti"></d-cite>
</h3>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/blog/normal-estimation/nestinet.png">
    </div>
</div>
<div class="caption">
    Nesti-Net Architecture.
</div>
<ul>
  <li>Nesti-Net estimates <strong>unoriented</strong> normals for each point. It:
    <ol>
      <li>computes a multi-scale representation for the points’ neighborhood</li>
      <li>regresses the normal vector (Ni, Nj, Nk) using a <strong>mixture of 3D CNN expert networks</strong>
</li>
      <li>selects the best expert using a <strong>selection manager</strong> and outputs its prediction</li>
    </ol>
  </li>
  <li>The multi-scale representation is termed as Multi-scale Point Statistics (MuPS) which is computed by taking multi-scaled neighborhood representations and converting to <code class="language-plaintext highlighter-rouge">3DfMV</code> <d-cite key="ben20173d"></d-cite> <strong>(fisher vectors)</strong> representation.
    <ul>
      <li>For computing the 3DfMV <d-cite key="ben20173d"></d-cite>, a coarse Gaussian grid is laid over the neighborhood.</li>
      <li>This representation is permutation-invariant, sample-size independent and thus allows the otherwise unstructured, unordered input (point cloud) suitable for applying 3D CNN.</li>
    </ul>
  </li>
  <li>The usage of <em>Mixture of Experts <code class="language-plaintext highlighter-rouge">(MoE)</code></em> network and a scale selection manager essentially encourages <strong>specialization</strong>, allowing Nesti-Net to learn the neighborhood size that minimizes the normal estimation error, rather than averaging on multi-scales.
    <ul>
      <li>It is explored what different experts learn: eg. for high curvature areas, output from expert dealing with small radius is selected.</li>
      <li>The selection manager sets a dynamic behavior wherein an expert is chosen to output depending on the probability of it estimating correctly.</li>
    </ul>
  </li>
  <li>Nesti-Net is <code class="language-plaintext highlighter-rouge">not</code> an end-to-end network. It involves a pre-processing step of computing MuPS features <code class="language-plaintext highlighter-rouge">(4D vector)</code> before passing to the MoE network, which involves computing Fisher Vectors using GMM.</li>
</ul>

<div class="l-body"><hr style="margin:0;"></div>

<!------- LPFC ------->
<p><a name="lpfc"></a></p>
<h3 id="local-plane-constraint-and-multi-scale-selection-">Local Plane Constraint and Multi-Scale Selection <d-cite key="zhou2020normal"></d-cite>
</h3>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/blog/normal-estimation/lpfc.png">
    </div>
</div>
<div class="caption">
    Architecture
</div>
<ul>
  <li>The paper presents <strong>Local Plane Feature Constraint</strong> (LPFC) mechanism to improve on the estimation of unoriented normals. The main idea of LPFC is to learn which points <em>really</em> are part of the local patch, as opposed to the outliers or the “error points”.</li>
  <li>The <strong>binary classification</strong> mechanism uses a threshold to determine if the point really lies on the local-plane (patch) and whether it should contribute towards estimating the true normal at the center of the patch.</li>
  <li>It calculates <code class="language-plaintext highlighter-rouge">L2</code> distance for each of the point on the patch from the center point to determine how aligned they are with the center, and outputs 0 or 1 based on a threshold.</li>
  <li>This obtained <strong>plane estimation vector</strong> is concatenated with global feature vector of the patch to estimate the normal.</li>
  <li>Using <strong>plane-aware features</strong> obtained with LPFC allows for more robust results, as it removes the outliers (error points) from the patch (in prediction).</li>
  <li>Overall, instead of just using regression loss, it uses <strong>multi-task loss</strong> in a joint-learning fashion (classification + regression).</li>
  <li>Multi-scale version of this approach has also been presented.</li>
</ul>

<div class="l-body"><hr style="margin:0;"></div>

<!------- gcn-based ------->
<p><a name="gcn"></a></p>
<h3 id="graph-convolutional-networks-gcn-based-">(Graph Convolutional Networks) GCN-based <d-cite key="pistilli2020point"></d-cite>
</h3>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="/assets/img/blog/normal-estimation/gcn.png">
    </div>
</div>
<div class="caption">
    Proposed Architecture
</div>
<ul>
  <li>Utilizes GCNs to extract neighborhood representation, which tend to be based on the intuition behind the standard CNNs: weight reuse, locality, hierarchical compositionality
    <ul>
      <li>GCNs are a powerful tool to aggregate and build on local information.</li>
    </ul>
  </li>
  <li>Design
    <ul>
      <li>Involves dynamic graph construction (<strong>Edge-Conditioned Convolution</strong> <d-cite key="simonovsky2017dynamic"></d-cite> ) which helps in accumulating global information in later layers</li>
      <li>Involves <strong>residual blocks</strong> of GCN layers</li>
      <li>Includes <strong>edge attention</strong> term in neighborhood aggregation update.</li>
    </ul>
  </li>
  <li>Instead of estimating normals only for the central points of the patch (eg. in PCPNet), this computes normals for all the points in the patch.</li>
  <li>In the loss function, it takes a subset of P points from the patch to avoid estimation errors due to points far away from the center (border effects)</li>
</ul>

<hr>

<p><img class="emoji" title=":bulb:" alt=":bulb:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4a1.png" height="20" width="20"> <code class="language-plaintext highlighter-rouge">TODO: complete citations @me</code></p>

<p><img class="emoji" title=":loudspeaker:" alt=":loudspeaker:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4e2.png" height="20" width="20"> <code class="language-plaintext highlighter-rouge">know of any other interesting architectures? discussion section is below</code> <a href="#disqus_thread"><img class="emoji" title=":arrow_down:" alt=":arrow_down:" src="https://github.githubassets.com/images/icons/emoji/unicode/2b07.png" height="20" width="20"></a></p>

      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

    </div>

	<!-- Disqus -->
	  
	  <div class="l-body">
		<div id="disqus_thread"></div>
		<script type="text/javascript">
		  var disqus_shortname  = 'pratulyab';
		  var disqus_identifier = '/blog/2020/normal-estimation-review';
		  var disqus_title      = "Surface Normal Estimation in Point Clouds";
		  (function() {
			var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
			dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
			(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
		  })();
		</script>
		<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a>
</noscript>
	  </div>
	  


    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    © Copyright 2020 Pratulya  Bubna.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
  </div>
</footer>



  </body>

  <d-bibliography src="/assets/bibliography/2020-11-15-normal-estimation-review.bib">
  </d-bibliography>

</html>
